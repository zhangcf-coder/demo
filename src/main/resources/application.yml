spring:
  redis:
    database: 0
    timeout: 3000
#    sentinel:    #哨兵模式
#      master: mymaster #主服务器所在集群名称
#      nodes: 82.157.171.43:26379,82.157.171.43:26380,82.157.171.43:26381
    cluster:
      nodes: 82.157.171.43:8001,82.157.171.43:8002,82.157.171.43:8003,82.157.171.43:8004,82.157.171.43:8005,82.157.171.43:8006
    lettuce:
      pool:
        max-idle: 50
        min-idle: 10
        max-active: 100
        max-wait: 1000
#  datasource:
#    primary:
#      username: root
#      password: root@123
#      jdbcUrl: jdbc:mysql://bpit-finace-dev-mysql-master0001.bcc-szwg.baidu.com:8806/legal_test
#      driverClassName: com.mysql.jdbc.Driver
#      type: com.alibaba.druid.pool.DruidDataSource
#    secondary:
#      username: root
#      password: root@123
#      jdbcUrl: jdbc:mysql://bpit-finace-dev-mysql-master0001.bcc-szwg.baidu.com:8806/legal_test
##      driverClassName: com.alibaba.druid.pool.DruidDataSource
#    druid:
#      # 连接池初始化大小，最小，最大
#      initial-size: 20
#      min-idle: 50
#      max-active: 350
#      # 获取链接配置时，最大等待时间
#      max-wait: 5000
#      # 空闲链接关闭检测时间 ms
#      time-between-eviction-runs-millis: 30000
#      # 单个链接的最小生存时间
#      min-evictable-idle-time-millis: 60000
#      # 链接存活验证语句
#      validation-query: SELECT 'x' FROM DUALS
#      # 是否需要在空闲一段时间后检测存活
#      test-while-idle: true
#      # 取出时是否需要检测存活
#      test-on-borrow: true
#      # 放回时时候需要检测存活
#      test-on-return: false
#      # 开启PreparedStatement 指定每个链接最多挂载 PSCache的大小
#      pool-prepared-statements: true
#      max-pool-prepared-statement-per-connection-size: 20
#      # 监控打印SQL的 filters wall用于防火墙
#      filters:
#        commons-log.connection-logger-name: stat,wall,log4j
#      # 开启慢SQL记录
#      connection-properties: druid.stat.mergeSql=true;druid.stat.slowSqlMillis=5000
    #    schema:
    #      - classpath:department.sql
  thymeleaf:
    cache: false
    encoding: UTF-8
    enabled: true
    mode: HTML
    prefix: classpath:/templates/
    suffix: .html
    servlet:
      content-type: text/html
  kafka:
    bootstrap-servers: 82.157.171.43:9092
    producer: # 生产者
      retries: 1 # 设置大于0的值，则客户端会将发送失败的记录重新发送
      batch-size: 16384
      buffer-memory: 33554432
      acks: 1
      # 指定消息key和消息体的编解码方式
      key-serializer: org.apache.kafka.common.serialization.StringSerializer
      value-serializer: org.apache.kafka.common.serialization.StringSerializer
    consumer:
      group-id: default-group
      enable-auto-commit: false
      auto-offset-reset: earliest
      key-deserializer: org.apache.kafka.common.serialization.StringDeserializer
      value-deserializer: org.apache.kafka.common.serialization.StringDeserializer
    listener:
      # 当每一条记录被消费者监听器（ListenerConsumer）处理之后提交
      # RECORD
      # 当每一批poll()的数据被消费者监听器（ListenerConsumer）处理之后提交
      # BATCH
      # 当每一批poll()的数据被消费者监听器（ListenerConsumer）处理之后，距离上次提交时间大于TIME时提交
      # TIME
      # 当每一批poll()的数据被消费者监听器（ListenerConsumer）处理之后，被处理record数量大于等于COUNT时提交
      # COUNT
      # TIME |　COUNT　有一个条件满足时提交
      # COUNT_TIME
      # 当每一批poll()的数据被消费者监听器（ListenerConsumer）处理之后, 手动调用Acknowledgment.acknowledge()后提交
      # MANUAL
      # 手动调用Acknowledgment.acknowledge()后立即提交，一般使用这种
      # MANUAL_IMMEDIATE
      ack-mode: manual_immediate
#配置mybatis
mybatis:
  #扫描xml文件
  mapper-locations: classpath:mapper/*.xml
  configuration:
    #开启驼峰命名法
    map-underscore-to-camel-case: true